{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5-UiDFir1s9",
        "outputId": "a544555e-60a9-44b0-fc70-a152e090eef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1 avg: 0.4991370000000013\n",
            "v_rand avg: 0.4992970000000033\n",
            "v_min avg: 0.037671999999976696\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "NUM_COINS = 1000\n",
        "FLIP_NUM = 10\n",
        "TRIALS = 100000\n",
        "\n",
        "def flip_coins(num_coins, num_flips):\n",
        "  #flip num_coins coins num_flips times: 0 = heads, 1 = tails\n",
        "  return np.random.randint(0, 2, size=(num_coins, num_flips))\n",
        "\n",
        "def get_three_coins():\n",
        "  #flip 1000 coins, 10 times each\n",
        "  flips = flip_coins(NUM_COINS, FLIP_NUM)\n",
        "  #calculate number of heads for each coin\n",
        "  #heads are 0 so count tails and subtract from total\n",
        "  heads_count = FLIP_NUM - flips.sum(axis=1)\n",
        "  #get first coin heads count\n",
        "  c_1 = heads_count[0] / FLIP_NUM\n",
        "  #random coin chosen\n",
        "  c_rand = heads_count[np.random.randint(0, NUM_COINS)] / FLIP_NUM\n",
        "  #coin with minimum frequency of heads\n",
        "  c_min = heads_count.min() / FLIP_NUM\n",
        "\n",
        "  return(c_1, c_rand, c_min)\n",
        "\n",
        "def main():\n",
        "  v_1_avg, v_rand_avg, v_min_avg = 0, 0, 0\n",
        "  #calculate v_1, v_rand, and v_min averages of 100,000 trials\n",
        "  for i in range(TRIALS):\n",
        "    v_1, v_rand, v_min = get_three_coins()\n",
        "    v_1_avg += v_1\n",
        "    v_rand_avg += v_rand\n",
        "    v_min_avg += v_min\n",
        "  #calculate the averages\n",
        "  v_1_avg /= TRIALS\n",
        "  v_rand_avg /= TRIALS\n",
        "  v_min_avg /= TRIALS\n",
        "\n",
        "  print(f'v1 avg: {v_1_avg}')\n",
        "  print(f'v_rand avg: {v_rand_avg}')\n",
        "  print(f'v_min avg: {v_min_avg}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "SPACE = [-1, 1]\n",
        "\n",
        "def generate_target_function():\n",
        "    #randomly pick two points to define target function\n",
        "    p1 = np.random.uniform(*SPACE, 2)\n",
        "    p2 = np.random.uniform(*SPACE, 2)\n",
        "\n",
        "    #define slope and intercept for the line\n",
        "    slope = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
        "    y_intercept = p1[1] - slope * p1[0]\n",
        "\n",
        "    #return the target function\n",
        "    return lambda x: slope * x + y_intercept\n",
        "\n",
        "#generate and store the target function\n",
        "TARGET = generate_target_function()\n",
        "\n",
        "#function to generate and sort the training data\n",
        "def prepare_data(N, target_function):\n",
        "    X_n = []\n",
        "    y_n = []\n",
        "    #generate the training data points randomly\n",
        "    for i in range(N):\n",
        "        new_pt = np.random.uniform(*SPACE, 2)  #generate random points\n",
        "        y = target_function(new_pt[0])\n",
        "\n",
        "        #append the feature vector [1, x, y] (1 is for the bias term)\n",
        "        X_n.append([1, new_pt[0], new_pt[1]])\n",
        "        #find the sign of the random data points\n",
        "        y_n.append(np.sign(new_pt[1] - y))\n",
        "    X_n = np.array(X_n)\n",
        "    y_n = np.array(y_n).reshape(-1, 1)\n",
        "    return X_n, y_n\n",
        "\n",
        "\n",
        "#function to find the weights using linear regression\n",
        "def linear_regression(X_n, y_n):\n",
        "  #find the psuedo inverse\n",
        "  psuedo_inverse = np.dot(np.linalg.inv(np.dot(X_n.T, X_n)), X_n.T)\n",
        "  #calculate the weights\n",
        "  w = np.dot(psuedo_inverse, y_n)\n",
        "  return w.T\n",
        "\n",
        "#function to classify points using weights based off of prediction\n",
        "def classify(X_n, w):\n",
        "  return np.sign(np.dot(X_n, w.T))\n",
        "\n",
        "#function to run everything 1000 times and calculate E_in using learned weights\n",
        "def run(N, trials, target_function):\n",
        "  E_in_tot = 0\n",
        "  #repeat for 1000 trials\n",
        "  for i in range(trials):\n",
        "    #generate training data\n",
        "    X_n, y_n = prepare_data(N, target_function)\n",
        "    w = linear_regression(X_n, y_n) #compute weights\n",
        "    y_predicted = classify(X_n, w)\n",
        "    #find E_in for the N(N=100) training data points\n",
        "    E_in = np.mean(y_predicted != y_n)\n",
        "    E_in_tot += E_in\n",
        "  #calculate average E_in\n",
        "  avg_E_in = E_in_tot / trials\n",
        "  return avg_E_in\n",
        "\n",
        "\n",
        "def main():\n",
        "  N = 100 #num of training points\n",
        "  trials = 1000 #num of trials\n",
        "  avg_E_in = run(N, trials, TARGET)\n",
        "  print(f'Average in-sample error: {avg_E_in}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oigz_yZuU7Yp",
        "outputId": "2a08bc6f-fa55-44c3-bc78-75a4713df124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average in-sample error: 0.02848999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to create the out of sample data and calculate E_out on it\n",
        "def out_of_sample(target_function, w, tests):\n",
        "  #generate a new set of test data\n",
        "  X_test, y_test = prepare_data(tests, target_function)\n",
        "  y_predicted = classify(X_test, w) #classify the test data\n",
        "  #calculate out-of-sample error\n",
        "  E_out = np.mean(y_predicted != y_test)\n",
        "  return E_out\n",
        "\n",
        "#function to run the entire process and calculate both E_in and E_out\n",
        "def new_run(N, tests, trials, target_function):\n",
        "  E_out_tot, E_in_tot = 0, 0\n",
        "  #repeat for specified number of trials\n",
        "  for i in range(trials):\n",
        "    #generate in-sample training data\n",
        "    X_n, y_n = prepare_data(N, target_function)\n",
        "    #compute the weights using linear regression on the training data\n",
        "    w = linear_regression(X_n, y_n)\n",
        "    y_predicted_in = classify(X_n, w)\n",
        "    E_in = np.mean(y_predicted_in != y_n) #calculate E_in\n",
        "    E_in_tot += E_in\n",
        "    E_out = out_of_sample(target_function, w, tests) #calculate E_out\n",
        "    E_out_tot += E_out\n",
        "\n",
        "  #compute avg E_in and E_out\n",
        "  avg_E_in = E_in_tot / trials\n",
        "  avg_E_out = E_out_tot / trials\n",
        "\n",
        "  return avg_E_in, avg_E_out\n",
        "\n",
        "\n",
        "def main():\n",
        "  N = 100 #num of training data points\n",
        "  trials = 1000 #num of trials to run\n",
        "  tests = 1000 #num of out of sample points\n",
        "  avg_E_in, avg_E_out = new_run(N, tests, trials, TARGET)\n",
        "  print(f\"avg in sample error: {avg_E_in}\")\n",
        "  print(f\"avg out of sample error: {avg_E_out}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqc32XDwa8X0",
        "outputId": "4189a9ce-9ba1-4e38-dbac-ebefd55ca1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg in sample error: 0.029269999999999994\n",
            "avg out of sample error: 0.036466999999999944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iterations = 10000 #max iteration limit to avoid infinite loop\n",
        "\n",
        "#function to find misclassified points\n",
        "def misclassified(a, b):\n",
        "    return np.where(a != b)[0]\n",
        "\n",
        "#perceptron learning algorithm\n",
        "def PLA(X_n, y_n, w):\n",
        "  count = 0\n",
        "  #repeat till convergence or max_iterations reached\n",
        "  while count < max_iterations:\n",
        "    #predict classifications based on current weights\n",
        "    predictions = classify(X_n, w)\n",
        "    #find misclassified points\n",
        "    missed = misclassified(y_n, predictions).tolist()\n",
        "    if not missed: #break if no misclassifications\n",
        "      break\n",
        "\n",
        "    #randomly select a misclassified point\n",
        "    rand_idx = np.random.choice(missed)\n",
        "    w = w + y_n[rand_idx] * X_n[rand_idx] #update weight vec\n",
        "\n",
        "    count += 1\n",
        "  return w, count\n",
        "\n",
        "#function to run PLA over multiple trials and calculate avg iterations\n",
        "def run_PLA(N, trials, target_function):\n",
        "  total_iterations = 0\n",
        "  #run for specified number of trials\n",
        "  for i in range(trials):\n",
        "    #generate training data\n",
        "    X_n, y_n = prepare_data(N, target_function)\n",
        "    #get initial weights from linear regression\n",
        "    w_initial = linear_regression(X_n, y_n)\n",
        "    #apply PLA and calculate num of iterations\n",
        "    w, iterations = PLA(X_n, y_n, w_initial)\n",
        "    total_iterations += iterations\n",
        "  #find average number of iterations across all trials\n",
        "  avg_iterations = total_iterations / trials\n",
        "\n",
        "  return avg_iterations\n",
        "\n",
        "\n",
        "def main():\n",
        "  N = 10 #num of training points\n",
        "  trials = 1000 #num of trials\n",
        "  #run PLA experiment\n",
        "  avg_iterations = run_PLA(N, trials, TARGET)\n",
        "  print(f'avg number of iterations: {avg_iterations}')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw8nwwc1DaIX",
        "outputId": "f8b3088e-89a4-49d4-9d34-dc942a13a546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg number of iterations: 3.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#define target function\n",
        "def target_func(x1, x2):\n",
        "  return np.sign(x1**2 + x2**2 - 0.6)\n",
        "\n",
        "#function to generate random data points and create noise\n",
        "def generate_data(N):\n",
        "  #generate random points\n",
        "  X = np.random.uniform(-1, 1, (N, 2))\n",
        "  y = target_func(X[:, 0], X[:, 1])\n",
        "  #introduce 10% noise by flipping the sign of 10% of the labels\n",
        "  noise_indices = np.random.choice(N, size=int(0.1 * N), replace=False)\n",
        "  y[noise_indices] *= -1\n",
        "  #add bias (1) to the feature vector\n",
        "  X = np.column_stack((np.ones(N), X))\n",
        "\n",
        "  return X, y\n",
        "\n",
        "#function to perform linear regression and calculate weights\n",
        "def lin_regression(X, y):\n",
        "  #find the psuedo inverse\n",
        "  psuedo_inverse = np.dot(np.linalg.inv(np.dot(X.T, X)), X.T)\n",
        "  #calculate the weights\n",
        "  w = np.dot(psuedo_inverse, y)\n",
        "  return w.T\n",
        "\n",
        "#function to classify data based on learned weights\n",
        "def classify(X_n, w):\n",
        "  return np.sign(np.dot(X_n, w.T))\n",
        "\n",
        "#function to run experiment and caculate avg in-sample error\n",
        "def run_expt(N, trials):\n",
        "  E_in_tot = 0\n",
        "\n",
        "  #repeate experiment specified number of times\n",
        "  for i in range(trials):\n",
        "    X, y = generate_data(N) #generate training data\n",
        "    w = lin_regression(X, y) #compute weights\n",
        "    y_predicted = classify(X, w) #predict classifications\n",
        "    #calculate in-sample error\n",
        "    E_in = np.mean(y_predicted != y)\n",
        "    E_in_tot += E_in\n",
        "  #return avg in-sample error\n",
        "  return E_in_tot / trials\n",
        "\n",
        "\n",
        "def main():\n",
        "  N = 1000 #number of data points to generate\n",
        "  trials = 1000 #number of trials\n",
        "  avg_E_in = run_expt(N, trials) #get avg E_in\n",
        "  print(f'avg in-sample error: {avg_E_in}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9l9XWt2U-tH",
        "outputId": "c9932d58-d8cc-46c8-b67e-780b44dd307f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg in-sample error: 0.5036839999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to apply nonlinear transformation\n",
        "def nonlinear_transformation(X):\n",
        "  x1 = X[:, 1]\n",
        "  x2 = X[:, 2]\n",
        "  #create new feature matrix as specified in problem\n",
        "  X_transformed = np.column_stack((np.ones(X.shape[0]), x1, x2, x1 * x2, x1**2, x2**2))\n",
        "\n",
        "  return X_transformed\n",
        "\n",
        "#function to compare learned hypothesis with predefined hypotheses\n",
        "def compare_hypothesis(X_transformed, y, w):\n",
        "  hypotheses = [\n",
        "    np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5]), #[a] hypothesis\n",
        "    np.array([-1, -0.05, 0.08, 0.13, 1.5, 15]), #[b] hypothesis\n",
        "    np.array([-1, -0.05, 0.08, 0.13, 15, 1.5]), #[c] hypothesis\n",
        "    np.array([-1, -1.5, 0.08, 0.13, 0.05, 0.05]), #[d] hypothesis\n",
        "    np.array([-1, -0.05, 0.08, 1.5, 0.15, 0.15]) #[e] hypothesis\n",
        "  ]\n",
        "  #get predictions from learned model\n",
        "  model_predictions = classify(X_transformed, w)\n",
        "  agreement_probs = []\n",
        "  #evaluate predictions of each hypothesis\n",
        "  for hypothesis in hypotheses:\n",
        "    #calculate predictions of specified hypothesis\n",
        "    hypothesis_predictions = np.sign(np.dot(X_transformed, hypothesis.T))\n",
        "    #calculate agreement between model's prediction and hypothesis prediction\n",
        "    agreement = np.mean(model_predictions == hypothesis_predictions)\n",
        "    agreement_probs.append(agreement)\n",
        "\n",
        "  return agreement_probs\n",
        "\n",
        "#function to run experiment on specified number of trials and data points\n",
        "def run(N, trials):\n",
        "  total_agree_prob = np.zeros(5)\n",
        "  #loop through specified number of trials\n",
        "  for i in range(trials):\n",
        "    X, y = generate_data(N) #generate training data\n",
        "    X_transformed = nonlinear_transformation(X) #apply nonlinear transform\n",
        "    w = lin_regression(X_transformed, y) #compute weights w/ linear regression\n",
        "    #compare with predefined hypotheses\n",
        "    agreement_probs = compare_hypothesis(X_transformed, y, w)\n",
        "    total_agree_prob += agreement_probs\n",
        "  #return avg agreement probabilities for all hypotheses\n",
        "  return total_agree_prob / trials\n",
        "\n",
        "def main():\n",
        "  N = 1000 #number of data points\n",
        "  trials = 1000 #number of trials\n",
        "  #find agreement probabilities for all hypotheses\n",
        "  agreement_probs = run(N, trials)\n",
        "  for i, prob in enumerate(agreement_probs):\n",
        "    print(f'hypothesis {i+1}: {prob}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RAG7Hw9WXp6",
        "outputId": "9f43ade7-aee0-45d5-def3-f2e75ae28c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hypothesis 1: 0.962229000000001\n",
            "hypothesis 2: 0.6635789999999997\n",
            "hypothesis 3: 0.6629049999999983\n",
            "hypothesis 4: 0.6319689999999993\n",
            "hypothesis 5: 0.5598759999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IGNORE THIS ONE"
      ],
      "metadata": {
        "id": "T2CCOa5YpWZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5])\n",
        "\n",
        "def estimate_E_out(tests, trials):\n",
        "  E_out_tot = 0\n",
        "  E_in_tot = 0\n",
        "\n",
        "  for i in range(trials):\n",
        "    X_train, y_train = generate_data(tests)\n",
        "\n",
        "    X_train_transformed = nonlinear_transformation(X_train)\n",
        "\n",
        "    w_transformed = lin_regression(X_train_transformed, y_train)\n",
        "\n",
        "    y_predicted_train = classify(X_train_transformed, w_transformed)\n",
        "\n",
        "    E_in = np.mean(y_predicted_train != y_train)\n",
        "    E_in_tot += E_in\n",
        "\n",
        "    X_test, y_test = generate_data(tests)\n",
        "\n",
        "    X_test_transformed = nonlinear_transformation(X_test)\n",
        "\n",
        "    y_predicted = classify(X_test_transformed, w_transformed)\n",
        "\n",
        "    E_out = np.mean(y_predicted != y_test)\n",
        "    E_out_tot += E_out\n",
        "\n",
        "  avg_E_in = E_in_tot / trials\n",
        "  avg_E_out = E_out_tot / trials\n",
        "  return avg_E_in, avg_E_out\n",
        "\n",
        "def main():\n",
        "  tests = 1000\n",
        "  trials = 1000\n",
        "  avg_E_in, avg_E_out = estimate_E_out(tests, trials)\n",
        "  print(f'avg in sample error: {avg_E_in}')\n",
        "  print(f'avg out of sample error: {avg_E_out}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTCe9ixHhBx8",
        "outputId": "3c3bc62e-6e0f-4e2d-f152-a9e73e085496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg in sample error: 0.12379699999999978\n",
            "avg out of sample error: 0.12649000000000007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define hypothesis from problem 9\n",
        "hypothesis = np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5])\n",
        "\n",
        "#function to estimate E_out\n",
        "def estimate_E_out(tests, trials):\n",
        "  E_out_tot = 0\n",
        "  #evaluate over specified number of trials\n",
        "  for i in range(trials):\n",
        "    #generate a new test dataset\n",
        "    X_test, y_test = generate_data(tests)\n",
        "    # apply the nonlinear transformation to test data\n",
        "    X_test_transformed = nonlinear_transformation(X_test)\n",
        "    #use the predefined hypothesis to classify test data\n",
        "    y_predicted = classify(X_test_transformed, hypothesis)\n",
        "    #calculate out-of-sample error\n",
        "    E_out = np.mean(y_predicted != y_test)\n",
        "    E_out_tot += E_out\n",
        "  #calculate the average out-of-sample error over all trials\n",
        "  avg_E_out = E_out_tot / trials\n",
        "  return avg_E_out\n",
        "\n",
        "def main():\n",
        "  tests = 1000  #number of test points to generate\n",
        "  trials = 1000  #number of trials to average error\n",
        "  avg_E_out = estimate_E_out(tests, trials)  #estimate out-of-sample error\n",
        "  print(f'average out of sample error: {avg_E_out}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjSQwg8npL3S",
        "outputId": "18b350cb-8abb-4082-9bc6-c2f3e49c9c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average out of sample error: 0.1427290000000002\n"
          ]
        }
      ]
    }
  ]
}